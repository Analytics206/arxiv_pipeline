{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ArXiv Pipeline - Neo4j Graph Analysis\n",
    "\n",
    "This notebook explores the graph relationships between papers, authors, and categories in the ArXiv dataset.\n",
    "\n",
    "Key analyses include:\n",
    "- Author collaboration networks\n",
    "- Category relationships\n",
    "- Citation networks\n",
    "- Path analysis between researchers\n",
    "- Community detection\n",
    "\n",
    "The notebook uses the Neo4j graph database where paper-author-category relationships are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx\n",
    "from neo4j import GraphDatabase\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (if present)\n",
    "load_dotenv()\n",
    "\n",
    "# Set Matplotlib config\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Neo4j Configuration\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "\n",
    "print(f\"Neo4j URI: {NEO4J_URI}\")\n",
    "print(f\"Neo4j User: {NEO4J_USER}\")\n",
    "\n",
    "# Function to run Cypher queries and return the results\n",
    "def run_query(query, params=None):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, params or {})\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "# Connect to Neo4j\n",
    "try:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    \n",
    "    # Test connection by getting database info\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"CALL dbms.components() YIELD name, versions RETURN name, versions\")\n",
    "        record = result.single()\n",
    "        print(f\"✅ Connected to Neo4j ({record['name']} {record['versions'][0]})\")\n",
    "        \n",
    "        # Get node counts by label\n",
    "        count_query = \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN labels(n)[0] AS label, count(*) AS count\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        counts = run_query(count_query)\n",
    "        counts_df = pd.DataFrame(counts)\n",
    "        \n",
    "        if not counts_df.empty:\n",
    "            print(\"\\nNode counts:\")\n",
    "            for _, row in counts_df.iterrows():\n",
    "                print(f\"- {row['label']}: {row['count']:,} nodes\")\n",
    "            \n",
    "        # Get relationship counts\n",
    "        rel_query = \"\"\"\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN type(r) AS relationship, count(*) AS count\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        rels = run_query(rel_query)\n",
    "        rels_df = pd.DataFrame(rels)\n",
    "        \n",
    "        if not rels_df.empty:\n",
    "            print(\"\\nRelationship counts:\")\n",
    "            for _, row in rels_df.iterrows():\n",
    "                print(f\"- {row['relationship']}: {row['count']:,} relationships\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to connect to Neo4j: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph Structure Overview\n",
    "\n",
    "Let's examine the overall structure of our graph database to understand the connections between papers, authors, and categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a schema visualization using NetworkX\n",
    "def visualize_schema():\n",
    "    schema_query = \"\"\"\n",
    "    CALL db.schema.visualization()\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(schema_query)\n",
    "            record = result.single()\n",
    "            \n",
    "            if record:\n",
    "                print(\"Schema visualization available in Neo4j Browser\")\n",
    "            \n",
    "            # Create a simple schema representation with NetworkX\n",
    "            G = nx.DiGraph()\n",
    "            \n",
    "            # Add nodes for each label\n",
    "            labels = [\"Paper\", \"Author\", \"Category\"]\n",
    "            label_colors = {\"Paper\": \"lightblue\", \"Author\": \"lightgreen\", \"Category\": \"salmon\"}\n",
    "            \n",
    "            # Add relationship information\n",
    "            relationships = [\n",
    "                (\"Author\", \"AUTHORED\", \"Paper\"),\n",
    "                (\"Paper\", \"IN_CATEGORY\", \"Category\"),\n",
    "                (\"Paper\", \"CITES\", \"Paper\")\n",
    "            ]\n",
    "            \n",
    "            # Create NetworkX graph\n",
    "            for label in labels:\n",
    "                G.add_node(label, color=label_colors[label])\n",
    "                \n",
    "            for src, rel, dst in relationships:\n",
    "                G.add_edge(src, dst, label=rel)\n",
    "            \n",
    "            # Visualize\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            pos = nx.spring_layout(G, seed=42)\n",
    "            \n",
    "            # Draw nodes\n",
    "            node_colors = [G.nodes[n]['color'] for n in G.nodes()]\n",
    "            nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=2000, alpha=0.8)\n",
    "            \n",
    "            # Draw edges\n",
    "            nx.draw_networkx_edges(G, pos, width=2, arrowsize=20, alpha=0.7)\n",
    "            \n",
    "            # Draw labels\n",
    "            nx.draw_networkx_labels(G, pos, font_size=12, font_weight=\"bold\")\n",
    "            \n",
    "            # Draw edge labels\n",
    "            edge_labels = {(src, dst): data['label'] for src, dst, data in G.edges(data=True)}\n",
    "            nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "            \n",
    "            plt.title(\"Graph Schema Visualization\", fontsize=16)\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing schema: {e}\")\n",
    "\n",
    "# Run schema visualization\n",
    "visualize_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Author Collaboration Networks\n",
    "\n",
    "Let's analyze how authors collaborate on papers. We'll look at:\n",
    "- Most connected authors (with highest number of collaborators)\n",
    "- Collaboration patterns\n",
    "- Visualization of collaboration networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Find top authors by paper count\n",
    "top_authors_query = \"\"\"\n",
    "MATCH (a:Author)-[:AUTHORED]->(p:Paper)\n",
    "WITH a, count(p) AS paper_count\n",
    "ORDER BY paper_count DESC\n",
    "LIMIT 20\n",
    "RETURN a.name AS author, paper_count\n",
    "\"\"\"\n",
    "\n",
    "top_authors = run_query(top_authors_query)\n",
    "top_authors_df = pd.DataFrame(top_authors)\n",
    "\n",
    "# Plot top authors if data exists\n",
    "if not top_authors_df.empty:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.barh(top_authors_df['author'], top_authors_df['paper_count'], color='steelblue')\n",
    "    plt.title('Top 20 Authors by Paper Count', fontsize=16)\n",
    "    plt.xlabel('Number of Papers', fontsize=14)\n",
    "    plt.ylabel('Author', fontsize=14)\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have highest count at the top\n",
    "\n",
    "    # Add count labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                 f\"{width}\", ha='left', va='center', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No author data found in the database\")\n",
    "\n",
    "# Find authors with the most collaborators\n",
    "top_collaborators_query = \"\"\"\n",
    "MATCH (a1:Author)-[:AUTHORED]->(:Paper)<-[:AUTHORED]-(a2:Author)\n",
    "WHERE a1 <> a2\n",
    "WITH a1, count(DISTINCT a2) AS collaborator_count\n",
    "ORDER BY collaborator_count DESC\n",
    "LIMIT 20\n",
    "RETURN a1.name AS author, collaborator_count\n",
    "\"\"\"\n",
    "\n",
    "top_collaborators = run_query(top_collaborators_query)\n",
    "top_collaborators_df = pd.DataFrame(top_collaborators)\n",
    "\n",
    "# Plot top collaborators if data exists\n",
    "if not top_collaborators_df.empty:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.barh(top_collaborators_df['author'], top_collaborators_df['collaborator_count'], color='forestgreen')\n",
    "    plt.title('Top 20 Authors by Number of Collaborators', fontsize=16)\n",
    "    plt.xlabel('Number of Collaborators', fontsize=14)\n",
    "    plt.ylabel('Author', fontsize=14)\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have highest count at the top\n",
    "\n",
    "    # Add count labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                 f\"{width}\", ha='left', va='center', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No collaboration data found in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract a subset of author collaboration network for visualization\n",
    "# Get authors with most collaborations for visualization\n",
    "collab_network_query = \"\"\"\n",
    "MATCH (a1:Author)-[:AUTHORED]->(:Paper)<-[:AUTHORED]-(a2:Author)\n",
    "WHERE a1 <> a2\n",
    "WITH a1, a2, count(*) AS collaboration_strength\n",
    "ORDER BY collaboration_strength DESC\n",
    "LIMIT 100\n",
    "RETURN a1.name AS source, a2.name AS target, collaboration_strength AS weight\n",
    "\"\"\"\n",
    "\n",
    "collaborations = run_query(collab_network_query)\n",
    "\n",
    "if collaborations:\n",
    "    # Create a NetworkX graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges with weights\n",
    "    for collab in collaborations:\n",
    "        G.add_edge(collab['source'], collab['target'], weight=collab['weight'])\n",
    "\n",
    "    # Remove isolated nodes\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "    # Calculate node degrees (for sizing)\n",
    "    node_degrees = dict(G.degree())\n",
    "\n",
    "    # Calculate node centrality for colors\n",
    "    centrality = nx.eigenvector_centrality_numpy(G, weight='weight')\n",
    "    max_centrality = max(centrality.values())\n",
    "    node_colors = [plt.cm.plasma(c/max_centrality) for c in centrality.values()]\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "\n",
    "    # Draw edges with varying thickness based on weight\n",
    "    edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    max_weight = max(edge_weights)\n",
    "    normalized_weights = [w/max_weight*4 for w in edge_weights]\n",
    "    nx.draw_networkx_edges(G, pos, width=normalized_weights, alpha=0.5, edge_color=\"gray\")\n",
    "\n",
    "    # Draw nodes with varying size based on degree\n",
    "    node_sizes = [v * 30 for v in node_degrees.values()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, alpha=0.8)\n",
    "\n",
    "    # Add labels only to nodes with high degree\n",
    "    threshold = np.percentile(list(node_degrees.values()), 75)  # Top 25% of nodes\n",
    "    large_nodes = {node: node for node, degree in node_degrees.items() if degree > threshold}\n",
    "    nx.draw_networkx_labels(G, pos, labels=large_nodes, font_size=10, font_weight=\"bold\")\n",
    "\n",
    "    plt.title(\"Author Collaboration Network\", fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Network contains {G.number_of_nodes()} authors and {G.number_of_edges()} collaboration links\")\n",
    "    \n",
    "    # Calculate and display some network metrics\n",
    "    print(\"\\nNetwork Metrics:\")\n",
    "    print(f\"Average degree: {2*G.number_of_edges()/G.number_of_nodes():.2f}\")\n",
    "    \n",
    "    # Try to calculate metrics that might fail\n",
    "    try:\n",
    "        print(f\"Network density: {nx.density(G):.4f}\")\n",
    "    except:\n",
    "        print(\"Network density calculation failed (network may be too large)\")\n",
    "        \n",
    "    try:\n",
    "        print(f\"Average clustering coefficient: {nx.average_clustering(G):.4f}\")\n",
    "    except:\n",
    "        print(\"Clustering coefficient calculation failed (network may be too large)\")\n",
    "else:\n",
    "    print(\"No collaboration data found for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract a subset of author collaboration network for visualization\n",
    "# Get authors with most collaborations for visualization\n",
    "collab_network_query = \"\"\"\n",
    "MATCH (a1:Author)-[:AUTHORED]->(:Paper)<-[:AUTHORED]-(a2:Author)\n",
    "WHERE a1 <> a2\n",
    "WITH a1, a2, count(*) AS collaboration_strength\n",
    "ORDER BY collaboration_strength DESC\n",
    "LIMIT 100\n",
    "RETURN a1.name AS source, a2.name AS target, collaboration_strength AS weight\n",
    "\"\"\"\n",
    "\n",
    "collaborations = run_query(collab_network_query)\n",
    "\n",
    "if collaborations:\n",
    "    # Create a NetworkX graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges with weights\n",
    "    for collab in collaborations:\n",
    "        G.add_edge(collab['source'], collab['target'], weight=collab['weight'])\n",
    "\n",
    "    # Remove isolated nodes\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "    # Calculate node degrees (for sizing)\n",
    "    node_degrees = dict(G.degree())\n",
    "\n",
    "    # Calculate node centrality for colors\n",
    "    centrality = nx.eigenvector_centrality_numpy(G, weight='weight')\n",
    "    max_centrality = max(centrality.values())\n",
    "    node_colors = [plt.cm.plasma(c/max_centrality) for c in centrality.values()]\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "\n",
    "    # Draw edges with varying thickness based on weight\n",
    "    edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    max_weight = max(edge_weights)\n",
    "    normalized_weights = [w/max_weight*4 for w in edge_weights]\n",
    "    nx.draw_networkx_edges(G, pos, width=normalized_weights, alpha=0.5, edge_color=\"gray\")\n",
    "\n",
    "    # Draw nodes with varying size based on degree\n",
    "    node_sizes = [v * 30 for v in node_degrees.values()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, alpha=0.8)\n",
    "\n",
    "    # Add labels only to nodes with high degree\n",
    "    threshold = np.percentile(list(node_degrees.values()), 75)  # Top 25% of nodes\n",
    "    large_nodes = {node: node for node, degree in node_degrees.items() if degree > threshold}\n",
    "    nx.draw_networkx_labels(G, pos, labels=large_nodes, font_size=10, font_weight=\"bold\")\n",
    "\n",
    "    plt.title(\"Author Collaboration Network\", fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Network contains {G.number_of_nodes()} authors and {G.number_of_edges()} collaboration links\")\n",
    "    \n",
    "    # Calculate and display some network metrics\n",
    "    print(\"\\nNetwork Metrics:\")\n",
    "    print(f\"Average degree: {2*G.number_of_edges()/G.number_of_nodes():.2f}\")\n",
    "    \n",
    "    # Try to calculate metrics that might fail\n",
    "    try:\n",
    "        print(f\"Network density: {nx.density(G):.4f}\")\n",
    "    except:\n",
    "        print(\"Network density calculation failed (network may be too large)\")\n",
    "        \n",
    "    try:\n",
    "        print(f\"Average clustering coefficient: {nx.average_clustering(G):.4f}\")\n",
    "    except:\n",
    "        print(\"Clustering coefficient calculation failed (network may be too large)\")\n",
    "else:\n",
    "    print(\"No collaboration data found for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Category Relationships\n",
    "\n",
    "Let's analyze how different research categories are related through papers that belong to multiple categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get category relationships\n",
    "category_relationships_query = \"\"\"\n",
    "MATCH (c1:Category)<-[:IN_CATEGORY]-(:Paper)-[:IN_CATEGORY]->(c2:Category)\n",
    "WHERE c1 <> c2\n",
    "WITH c1.name AS category1, c2.name AS category2, count(*) AS paper_count\n",
    "ORDER BY paper_count DESC\n",
    "LIMIT 50\n",
    "RETURN category1, category2, paper_count\n",
    "\"\"\"\n",
    "\n",
    "category_relationships = run_query(category_relationships_query)\n",
    "\n",
    "if category_relationships:\n",
    "    category_relationships_df = pd.DataFrame(category_relationships)\n",
    "    \n",
    "    # Display top category relationships\n",
    "    print(\"Top Category Relationships:\")\n",
    "    print(category_relationships_df.head(10))\n",
    "    \n",
    "    # Create a NetworkX graph for categories\n",
    "    cat_G = nx.Graph()\n",
    "\n",
    "    # Add edges with weights\n",
    "    for _, rel in category_relationships_df.iterrows():\n",
    "        cat_G.add_edge(rel['category1'], rel['category2'], weight=rel['paper_count'])\n",
    "\n",
    "    # Calculate node importance (for sizing)\n",
    "    node_importance = dict(nx.degree(cat_G, weight='weight'))\n",
    "    max_importance = max(node_importance.values()) if node_importance else 0\n",
    "\n",
    "    # Plot the category relationship graph\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    pos = nx.spring_layout(cat_G, k=0.3, iterations=50, seed=42)\n",
    "\n",
    "    # Draw edges with varying thickness based on weight\n",
    "    edge_weights = [cat_G[u][v]['weight'] for u, v in cat_G.edges()]\n",
    "    max_weight = max(edge_weights)\n",
    "    norm_weights = [w/max_weight * 5 for w in edge_weights]\n",
    "\n",
    "    nx.draw_networkx_edges(cat_G, pos, width=norm_weights, alpha=0.5, edge_color=\"gray\")\n",
    "\n",
    "    # Create a colormap based on node importance\n",
    "    node_colors = [plt.cm.viridis(imp / max_importance) for imp in node_importance.values()]\n",
    "    \n",
    "    # Draw nodes with varying size based on importance\n",
    "    node_sizes = [imp/max_importance * 1000 + 100 for imp in node_importance.values()]\n",
    "    nx.draw_networkx_nodes(cat_G, pos, node_size=node_sizes, node_color=node_colors, alpha=0.8)\n",
    "\n",
    "    # Add labels \n",
    "    nx.draw_networkx_labels(cat_G, pos, font_size=8, font_weight=\"bold\")\n",
    "\n",
    "    plt.title(\"Category Relationship Network\", fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate and display metrics about the category network\n",
    "    print(f\"\\nCategory network has {cat_G.number_of_nodes()} categories and {cat_G.number_of_edges()} relationships\")\n",
    "    print(f\"Network density: {nx.density(cat_G):.4f}\")\n",
    "    \n",
    "    # Find central categories using different centrality measures\n",
    "    print(\"\\nMost central categories:\")\n",
    "    \n",
    "    # Degree centrality\n",
    "    degree_cent = nx.degree_centrality(cat_G)\n",
    "    top_degree = sorted(degree_cent.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"By connections:\")\n",
    "    for cat, cent in top_degree:\n",
    "        print(f\"- {cat}: {cent:.4f}\")\n",
    "        \n",
    "    # Betweenness centrality\n",
    "    try:\n",
    "        between_cent = nx.betweenness_centrality(cat_G)\n",
    "        top_between = sorted(between_cent.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(\"\\nBy betweenness:\")\n",
    "        for cat, cent in top_between:\n",
    "            print(f\"- {cat}: {cent:.4f}\")\n",
    "    except:\n",
    "        print(\"\\nBetweenness centrality calculation failed (network may be too large)\")\n",
    "else:\n",
    "    print(\"No category relationship data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Paper Citation Network\n",
    "\n",
    "Let's analyze the citation network between papers, if available in our graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check if CITES relationships exist\n",
    "citation_check_query = \"\"\"\n",
    "MATCH ()-[r:CITES]->() \n",
    "RETURN count(r) as citation_count\n",
    "\"\"\"\n",
    "\n",
    "citation_check = run_query(citation_check_query)\n",
    "citation_count = citation_check[0]['citation_count'] if citation_check else 0\n",
    "\n",
    "if citation_count > 0:\n",
    "    print(f\"Found {citation_count} citation relationships in the database\")\n",
    "    \n",
    "    # Get top cited papers\n",
    "    top_cited_query = \"\"\"\n",
    "    MATCH (p:Paper)<-[r:CITES]-()\n",
    "    WITH p, count(r) AS citation_count\n",
    "    ORDER BY citation_count DESC\n",
    "    LIMIT 20\n",
    "    RETURN p.title AS paper_title, citation_count\n",
    "    \"\"\"\n",
    "    \n",
    "    top_cited = run_query(top_cited_query)\n",
    "    top_cited_df = pd.DataFrame(top_cited)\n",
    "    \n",
    "    # Plot top cited papers\n",
    "    if not top_cited_df.empty:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Truncate long titles\n",
    "        top_cited_df['short_title'] = top_cited_df['paper_title'].apply(lambda x: x[:50] + '...' if len(x) > 50 else x)\n",
    "        \n",
    "        bars = plt.barh(top_cited_df['short_title'], top_cited_df['citation_count'], color='purple')\n",
    "        plt.title('Top 20 Most Cited Papers', fontsize=16)\n",
    "        plt.xlabel('Number of Citations', fontsize=14)\n",
    "        plt.ylabel('Paper Title', fontsize=14)\n",
    "        plt.gca().invert_yaxis()  # Invert y-axis to have highest count at the top\n",
    "\n",
    "        # Add count labels\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            plt.text(width + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                     f\"{width}\", ha='left', va='center', fontweight='bold')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No citation relationships found in the database\")\n",
    "    \n",
    "    # If no citation data, show paper distribution by year instead\n",
    "    paper_by_year_query = \"\"\"\n",
    "    MATCH (p:Paper)\n",
    "    WHERE p.published_year IS NOT NULL\n",
    "    RETURN p.published_year AS year, count(*) AS paper_count\n",
    "    ORDER BY year\n",
    "    \"\"\"\n",
    "    \n",
    "    papers_by_year = run_query(paper_by_year_query)\n",
    "    papers_by_year_df = pd.DataFrame(papers_by_year)\n",
    "    \n",
    "    if not papers_by_year_df.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(papers_by_year_df['year'], papers_by_year_df['paper_count'], color='teal')\n",
    "        plt.title('Papers Published by Year', fontsize=16)\n",
    "        plt.xlabel('Year', fontsize=14)\n",
    "        plt.ylabel('Number of Papers', fontsize=14)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Try another query format if year isn't available\n",
    "        paper_count_query = \"\"\"\n",
    "        MATCH (p:Paper)\n",
    "        RETURN count(p) AS total_papers\n",
    "        \"\"\"\n",
    "        paper_count = run_query(paper_count_query)\n",
    "        print(f\"Total papers in database: {paper_count[0]['total_papers']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Path Analysis Between Researchers\n",
    "\n",
    "Let's explore the paths connecting researchers through collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to find shortest paths between authors\n",
    "def find_author_paths(author1, author2, max_depth=4):\n",
    "    path_query = f\"\"\"\n",
    "    MATCH path = shortestPath((a1:Author {{name: $author1}})-[:AUTHORED*1..{max_depth}]-(a2:Author {{name: $author2}}))\n",
    "    RETURN [node in nodes(path) WHERE node:Author | node.name] AS author_path,\n",
    "           [node in nodes(path) WHERE node:Paper | node.title] AS papers\n",
    "    \"\"\"\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        result = session.run(path_query, {\"author1\": author1, \"author2\": author2})\n",
    "        paths = [record.data() for record in result]\n",
    "        return paths\n",
    "\n",
    "# Get list of top authors for demo\n",
    "top_authors_query = \"\"\"\n",
    "MATCH (a:Author)-[:AUTHORED]->(p:Paper)\n",
    "WITH a, count(p) AS paper_count\n",
    "ORDER BY paper_count DESC\n",
    "LIMIT 10\n",
    "RETURN a.name AS author\n",
    "\"\"\"\n",
    "\n",
    "top_authors_list = run_query(top_authors_query)\n",
    "top_authors_names = [author['author'] for author in top_authors_list]\n",
    "\n",
    "if len(top_authors_names) >= 2:\n",
    "    # Choose two authors to find paths between\n",
    "    author1 = top_authors_names[0]\n",
    "    author2 = top_authors_names[-1]\n",
    "    \n",
    "    print(f\"Finding collaboration paths between {author1} and {author2}\")\n",
    "    \n",
    "    paths = find_author_paths(author1, author2)\n",
    "    \n",
    "    if paths:\n",
    "        print(f\"Found {len(paths)} paths connecting these authors\\n\")\n",
    "        \n",
    "        for i, path in enumerate(paths):\n",
    "            print(f\"Path {i+1}:\")\n",
    "            \n",
    "            author_path = path['author_path']\n",
    "            papers = path['papers']\n",
    "            \n",
    "            # Print the chain of authors\n",
    "            print(\" -> \".join(author_path))\n",
    "            \n",
    "            # Print the papers connecting them\n",
    "            print(\"\\nConnecting papers:\")\n",
    "            for paper in papers:\n",
    "                print(f\"- {paper}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        # Visualize the first path\n",
    "        if paths and 'author_path' in paths[0]:\n",
    "            G = nx.Graph()\n",
    "            \n",
    "            # Add author nodes\n",
    "            authors = paths[0]['author_path']\n",
    "            for author in authors:\n",
    "                G.add_node(author, type='author')\n",
    "            \n",
    "            # Add paper nodes and edges\n",
    "            papers = paths[0]['papers']\n",
    "            for i, paper in enumerate(papers):\n",
    "                short_title = paper[:30] + \"...\" if len(paper) > 30 else paper\n",
    "                G.add_node(short_title, type='paper')\n",
    "                \n",
    "                # Connect paper to authors\n",
    "                if i == 0:\n",
    "                    G.add_edge(authors[0], short_title)\n",
    "                    G.add_edge(authors[1], short_title)\n",
    "                else:\n",
    "                    G.add_edge(authors[i], short_title)\n",
    "                    G.add_edge(authors[i+1], short_title)\n",
    "            \n",
    "            # Visualize\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(G, seed=42)\n",
    "            \n",
    "            # Draw with different colors for authors and papers\n",
    "            author_nodes = [n for n, attr in G.nodes(data=True) if attr.get('type') == 'author']\n",
    "            paper_nodes = [n for n, attr in G.nodes(data=True) if attr.get('type') == 'paper']\n",
    "            \n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=author_nodes, node_color='lightblue', \n",
    "                                   node_size=700, alpha=0.8)\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=paper_nodes, node_color='lightgreen', \n",
    "                                   node_size=500, alpha=0.8, node_shape='s')\n",
    "            \n",
    "            nx.draw_networkx_edges(G, pos, width=1.5, alpha=0.7)\n",
    "            nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "            \n",
    "            plt.title(f\"Collaboration Path from {author1} to {author2}\", fontsize=16)\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(f\"No paths found between {author1} and {author2} within 4 hops\")\n",
    "else:\n",
    "    print(\"Not enough authors in the database to perform path analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Community Detection\n",
    "\n",
    "Let's identify research communities within our co-authorship network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract a larger co-authorship network for community detection\n",
    "community_network_query = \"\"\"\n",
    "MATCH (a1:Author)-[:AUTHORED]->(:Paper)<-[:AUTHORED]-(a2:Author)\n",
    "WHERE a1 <> a2\n",
    "WITH a1, a2, count(*) AS collaboration_strength\n",
    "WHERE collaboration_strength > 1\n",
    "RETURN a1.name AS source, a2.name AS target, collaboration_strength AS weight\n",
    "LIMIT 500\n",
    "\"\"\"\n",
    "\n",
    "community_data = run_query(community_network_query)\n",
    "\n",
    "if community_data:\n",
    "    # Create NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges with weights\n",
    "    for collab in community_data:\n",
    "        G.add_edge(collab['source'], collab['target'], weight=collab['weight'])\n",
    "    \n",
    "    # Remove isolated nodes\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    \n",
    "    print(f\"Community analysis network has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    \n",
    "    # Try to detect communities using NetworkX's algorithms\n",
    "    try:\n",
    "        from networkx.algorithms import community\n",
    "        \n",
    "        # Use Clauset-Newman-Moore greedy modularity maximization\n",
    "        communities = list(community.greedy_modularity_communities(G))\n",
    "        \n",
    "        print(f\"Detected {len(communities)} communities\")\n",
    "        print(\"\\nTop communities by size:\")\n",
    "        \n",
    "        # Print top 5 communities by size\n",
    "        for i, comm in enumerate(sorted(communities, key=len, reverse=True)[:5]):\n",
    "            print(f\"Community {i+1}: {len(comm)} members\")\n",
    "            # Print sample members\n",
    "            sample_members = list(comm)[:3]\n",
    "            print(f\"Sample members: {', '.join(sample_members)}...\")\n",
    "        \n",
    "        # Visualize communities\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "        \n",
    "        # Assign colors to communities\n",
    "        community_map = {}\n",
    "        colors = plt.cm.tab20.colors\n",
    "        \n",
    "        for i, comm in enumerate(communities):\n",
    "            for node in comm:\n",
    "                community_map[node] = i\n",
    "        \n",
    "        # Get colors based on community\n",
    "        node_colors = [colors[community_map[n] % len(colors)] for n in G.nodes()]\n",
    "        \n",
    "        # Draw network with community colors\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=100, alpha=0.8)\n",
    "        nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.3, edge_color=\"gray\")\n",
    "        \n",
    "        # Label only the highest degree nodes\n",
    "        degrees = dict(G.degree())\n",
    "        top_nodes = {n: n for n, d in sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:20]}\n",
    "        nx.draw_networkx_labels(G, pos, labels=top_nodes, font_size=8, font_weight=\"bold\")\n",
    "        \n",
    "        plt.title(\"Author Communities in Co-authorship Network\", fontsize=16)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Community detection failed: {e}\")\n",
    "        print(\"Falling back to simpler network visualization\")\n",
    "        \n",
    "        # Simple network visualization without community detection\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "        \n",
    "        # Calculate node degrees for sizing\n",
    "        node_degrees = dict(G.degree())\n",
    "        node_sizes = [v * 20 for v in node_degrees.values()]\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='lightblue', alpha=0.8)\n",
    "        nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.3, edge_color=\"gray\")\n",
    "        \n",
    "        # Label only the highest degree nodes\n",
    "        top_nodes = {n: n for n, d in sorted(node_degrees.items(), key=lambda x: x[1], reverse=True)[:20]}\n",
    "        nx.draw_networkx_labels(G, pos, labels=top_nodes, font_size=8, font_weight=\"bold\")\n",
    "        \n",
    "        plt.title(\"Co-authorship Network\", fontsize=16)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for community detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusion\n",
    "\n",
    "Our analysis of the ArXiv graph database has revealed:\n",
    "\n",
    "1. **Graph Structure**: The database contains [insert node counts] nodes and [insert relationship counts] relationships\n",
    "2. **Author Collaboration**: We identified key collaborative networks and most connected authors\n",
    "3. **Category Relationships**: The most closely related research categories are [insert findings]\n",
    "4. **Citation Patterns**: [Insert findings on citation patterns if available]\n",
    "5. **Research Communities**: We detected [insert number] distinct research communities\n",
    "\n",
    "These insights can guide researchers in identifying collaboration opportunities and understanding the structure of the research landscape represented in our ArXiv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Close Neo4j connection\n",
    "driver.close()\n",
    "print(\"Neo4j connection closed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
