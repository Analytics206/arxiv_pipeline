{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArXiv Pipeline - MongoDB Analysis (Simple Version)\n",
    "\n",
    "This notebook explores and visualizes the paper metadata stored in MongoDB.\n",
    "\n",
    "Key analyses include:\n",
    "- Paper publication trends over time\n",
    "- Author analytics and rankings\n",
    "- Category distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (if present)\n",
    "load_dotenv()\n",
    "\n",
    "# Set Matplotlib config\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB Configuration\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017/\")\n",
    "MONGO_DB = os.getenv(\"MONGO_DB\", \"arxiv_papers\")\n",
    "\n",
    "print(f\"MongoDB URI: {MONGO_URI}\")\n",
    "print(f\"MongoDB Database: {MONGO_DB}\")\n",
    "\n",
    "# Connect to MongoDB\n",
    "try:\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[MONGO_DB]\n",
    "    # Test connection\n",
    "    server_info = client.server_info()\n",
    "    print(f\"✅ Connected to MongoDB (version: {server_info.get('version')})\")\n",
    "    \n",
    "    # Get collection stats\n",
    "    print(\"\\nCollection statistics:\")\n",
    "    collections = db.list_collection_names()\n",
    "    for collection in collections:\n",
    "        count = db[collection].count_documents({})\n",
    "        print(f\"- {collection}: {count:,} documents\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to connect to MongoDB: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paper Publication Trends Over Time\n",
    "\n",
    "Let's analyze how the publication volume has changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for time series analysis\n",
    "papers_df = pd.DataFrame(list(db.papers.find({}, {'_id': 1, 'id': 1, 'title': 1, 'authors': 1, 'categories': 1, 'update_date': 1, 'published': 1})))\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "papers_df['published_date'] = pd.to_datetime(papers_df['published'], errors='coerce')\n",
    "papers_df['year'] = papers_df['published_date'].dt.year\n",
    "papers_df['month'] = papers_df['published_date'].dt.month\n",
    "papers_df['year_month'] = papers_df['published_date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Get papers per year\n",
    "papers_per_year = papers_df['year'].value_counts().sort_index()\n",
    "\n",
    "# Plot papers per year\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = papers_per_year.plot(kind='bar', color='steelblue')\n",
    "plt.title('Number of Papers Published per Year', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of Papers', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add data labels on top of each bar\n",
    "for i, v in enumerate(papers_per_year):\n",
    "    ax.text(i, v + 10, f\"{v:,}\", ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Author Analytics\n",
    "\n",
    "Let's analyze the most prolific authors and co-authorship patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract all authors from papers\n",
    "def extract_authors(papers_df):\n",
    "    all_authors = []\n",
    "    author_paper_count = Counter()\n",
    "    \n",
    "    for _, paper in papers_df.iterrows():\n",
    "        if 'authors' in paper and paper['authors']:\n",
    "            paper_authors = paper['authors']\n",
    "            # Add to all authors list\n",
    "            all_authors.extend(paper_authors)\n",
    "            # Count papers per author\n",
    "            for author in paper_authors:\n",
    "                author_paper_count[author] += 1\n",
    "    \n",
    "    return all_authors, author_paper_count\n",
    "\n",
    "# Get author data\n",
    "all_authors, author_paper_count = extract_authors(papers_df)\n",
    "\n",
    "# Most prolific authors (top 20)\n",
    "top_authors = pd.DataFrame(author_paper_count.most_common(20), \n",
    "                           columns=['Author', 'Paper Count'])\n",
    "\n",
    "# Plot top authors\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.barh(top_authors['Author'], top_authors['Paper Count'], color='steelblue')\n",
    "plt.title('Top 20 Most Prolific Authors', fontsize=16)\n",
    "plt.xlabel('Number of Papers', fontsize=14)\n",
    "plt.ylabel('Author', fontsize=14)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have highest count at the top\n",
    "\n",
    "# Add count labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "             f\"{width:,}\", ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Category Distribution Analysis\n",
    "\n",
    "Let's analyze the distribution of categories across papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract all categories from papers\n",
    "def extract_categories(papers_df):\n",
    "    all_categories = []\n",
    "    category_paper_count = Counter()\n",
    "    \n",
    "    for _, paper in papers_df.iterrows():\n",
    "        if 'categories' in paper and paper['categories']:\n",
    "            paper_cats = paper['categories']\n",
    "            # Add to all categories list\n",
    "            all_categories.extend(paper_cats)\n",
    "            # Count papers per category\n",
    "            for cat in paper_cats:\n",
    "                category_paper_count[cat] += 1\n",
    "    \n",
    "    return all_categories, category_paper_count\n",
    "\n",
    "# Get category data\n",
    "all_categories, category_paper_count = extract_categories(papers_df)\n",
    "\n",
    "# Top categories (top 20)\n",
    "top_categories = pd.DataFrame(category_paper_count.most_common(20), \n",
    "                             columns=['Category', 'Paper Count'])\n",
    "\n",
    "# Plot top categories\n",
    "plt.figure(figsize=(14, 10))\n",
    "bars = plt.barh(top_categories['Category'], top_categories['Paper Count'], color='darkorange')\n",
    "plt.title('Top 20 Most Common Categories', fontsize=16)\n",
    "plt.xlabel('Number of Papers', fontsize=14)\n",
    "plt.ylabel('Category', fontsize=14)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have highest count at the top\n",
    "\n",
    "# Add count labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "             f\"{width:,}\", ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Database Health and Performance Metrics\n",
    "\n",
    "Let's check database health metrics and collection stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database statistics\n",
    "try:\n",
    "    db_stats = db.command(\"dbStats\")\n",
    "    \n",
    "    # Extract key metrics\n",
    "    metrics = {\n",
    "        \"Collections\": db_stats['collections'],\n",
    "        \"Objects\": db_stats['objects'],\n",
    "        \"Data Size (MB)\": round(db_stats['dataSize'] / (1024 * 1024), 2),\n",
    "        \"Storage Size (MB)\": round(db_stats['storageSize'] / (1024 * 1024), 2),\n",
    "        \"Indexes\": db_stats['indexes'],\n",
    "        \"Index Size (MB)\": round(db_stats['indexSize'] / (1024 * 1024), 2)\n",
    "    }\n",
    "    \n",
    "    print(\"MongoDB Database Statistics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"- {key}: {value:,}\")\n",
    "    \n",
    "    # Get collection stats\n",
    "    print(\"\\nCollection Statistics:\")\n",
    "    collections = db.list_collection_names()\n",
    "    for collection in collections:\n",
    "        stats = db.command(\"collStats\", collection)\n",
    "        print(f\"\\n{collection}:\")\n",
    "        print(f\"- Document Count: {stats['count']:,}\")\n",
    "        print(f\"- Data Size: {stats['size'] / (1024 * 1024):.2f} MB\")\n",
    "        print(f\"- Storage Size: {stats['storageSize'] / (1024 * 1024):.2f} MB\")\n",
    "        print(f\"- Index Size: {stats['totalIndexSize'] / (1024 * 1024):.2f} MB\")\n",
    "        print(f\"- Avg Document Size: {stats.get('avgObjSize', 0) / 1024:.2f} KB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error getting database statistics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Conclusions\n",
    "\n",
    "Based on our analysis of the ArXiv paper metadata in MongoDB, we've observed:\n",
    "\n",
    "1. **Publication Trends**: [Add observation about publication trends]\n",
    "2. **Author Patterns**: [Add observation about author patterns]\n",
    "3. **Category Distribution**: [Add observation about category distribution]\n",
    "4. **Database Performance**: [Add observation about database metrics]\n",
    "\n",
    "These insights can help inform research priorities and future enhancements to the ArXiv pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close MongoDB connection\n",
    "client.close()\n",
    "print(\"MongoDB connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
